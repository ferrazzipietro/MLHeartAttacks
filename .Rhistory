library(parallelMap)
parallelStartSocket(4) # start in socket mode and create 2 processes on localhost
set.seed(12345)
bmr_classif <- benchmark(learners    = learners,
tasks       = classif_task,
resamplings = desc_inner,
measures    = classif_measures,
models      = TRUE,
show.info   = TRUE)
parallelStop()
data_fs <- data %>% dplyr::select(-TIME)
fs_task <- makeClassifTask(id = "HeartFailure", data = data_fs, target = "Event", positive = 1)
library(FSelectorRcpp)
fv <- generateFilterValuesData(fs_task, method = "FSelectorRcpp_information.gain")
plotFilterValues(fv, feat.type.cols = TRUE) + scale_fill_brewer(palette="Blues") + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ggtitle("Filter Selection \n Information Gain")
data_fs <- data %>% dplyr::select(Creatinine, Ejection.Fraction, Event, Age)
fs_task <- makeClassifTask(id = "HeartFailure", data = data_fs, target = "Event", positive = 1)
set.seed(12345)
desc_inner_fs <- makeResampleInstance("RepCV", reps = 5,  folds = 2, task = fs_task, stratify = TRUE)
# https://mlr.mlr-org.com/articles/tutorial/integrated_learners.html
# Using the same learners defined in previous chunk
parallelStartSocket(4) # start in socket mode and create 2 processes on localhost
set.seed(12345)
bmr_fs <- benchmark(learners    = learners,
tasks       = fs_task,
resamplings = desc_inner_fs,
measures    = classif_measures,
models      = TRUE,
show.info   = FALSE)
parallelStop()
bp1 <- plotBMRBoxplots(bmr_classif,
measure   = tpr,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(fill = learner.id)  +
labs(x = "", y = "True Positive Rate") + scale_fill_brewer(palette="Blues")+
ylim(0,0.8) + ggtitle("True positive rate with all the features")
bp3 <- plotBMRBoxplots(bmr_fs,
measure   = tpr,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(fill = learner.id)  +
labs(x = "", y = "True Positive Rate (FSel)") + scale_fill_brewer(palette="Blues") +
ylim(0,0.8) + ggtitle("True positive rate with selected features")
ggarrange(bp1, bp3, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bls <- list(makeLearner("classif.kknn"),
makeLearner("classif.rpart"),
makeLearner("classif.randomForest"),
makeLearner("classif.ranger"),
makeLearner("classif.xgboost", eval_metric = "aucpr"),
makeLearner("classif.neuralnet"))
lrn <- makeModelMultiplexer(bls)
# Parameter Space (all together, divided by learner inside)
ps <- makeModelMultiplexerParamSet(
multiplexer = lrn,
classif.kknn = makeParamSet(makeIntegerParam("k", lower = 5, upper = 15)), # Default is 7-
classif.rpart = makeParamSet(makeIntegerParam("minsplit", lower = 15, upper = 35), # Default is 20
makeIntegerParam("maxdepth", lower = 15, upper = 50)), # Default is 30
classif.randomForest = makeParamSet(makeIntegerParam("ntree", lower = 200, upper = 700), #Default is 500
makeIntegerParam("mtry",lower = 1, upper = 2), #Default is floor(sy,qrt(features/3)), cannot be larger than number of variables
makeIntegerParam("nodesize", lower = 1, upper = 50)), #Default is 1
classif.ranger = makeParamSet(makeIntegerParam("mtry", lower = 1, upper = 2), # Same parameters as randomForest
makeIntegerParam("num.trees", lower = 200, upper = 700),
makeIntegerParam("min.node.size", lower = 1, upper = 50)),
classif.xgboost = makeParamSet(makeNumericParam("eta", lower = 0.2, upper = 0.5), # Default is 0.3
makeIntegerParam("nrounds", lower = 4, upper = 10), # Default is
makeIntegerParam("max_depth", lower = 3, upper = 10)), # Default is 6
classif.neuralnet = makeParamSet(makeIntegerVectorParam("hidden", len = 1, lower = 1, upper = 10),
makeNumericParam("threshold", lower = 2, upper = 5, trafo = function(x) {10^x}),
makeNumericParam("stepmax", lower = 2, upper = 3, trafo = function(x) {10^x}))
)
# Random Search
control_grid <- makeTuneControlRandom(maxit = 500L) # Default is 100, split between the amount of learners
parallelStartSocket(5) # start in socket mode and create 2 processes on localhost
set.seed(12345)
tuning_results_all <- tuneParams(learner = lrn,
task = classif_task,
resampling = desc_inner,
par.set = ps,
control = control_grid,
measures = list(acc, tpr),
show.info = TRUE)
set.seed(12345)
tuning_results_fs <- tuneParams(learner = lrn,
task = fs_task,
resampling = desc_inner,
par.set = ps,
control = control_grid,
measures = list(acc, tpr),
show.info = TRUE)
parallelStop()
# Obtaining best iteration for each learner (selecting features)
res_iters_fs <- getTuneResultOptPath(tuning_results_fs)
best_res <- res_iters_fs %>% group_by(selected.learner) %>% slice(which.max(tpr.test.mean)) %>%
relocate(tpr.test.mean, .after = selected.learner)
library(reshape)
options(scipen=999)
temp <- melt(as.data.frame(best_res)) %>% dplyr::select(-error.message) %>% drop_na()
tpr.test <- temp %>% filter(grepl("tpr", variable)) %>% dplyr::rename(tpr = value) %>% dplyr::select(-variable)
hyperparam <- temp %>% filter(grepl("classif", variable))
tuning_res <- full_join(hyperparam, tpr.test) %>%
mutate(parameter = ifelse(grepl("\\.", variable), sub(".*\\.(.*)", "\\1", variable), "")) %>%
dplyr::select(selected.learner, tpr, parameter, value)
rm(temp, tpr.test, hyperparam)
#tuning_res
# The outer partitioning was defined in the beginning of the document, we just have to update the preprocess of the data
final_data <- as.data.frame(tot) %>% dplyr::select(Creatinine, Ejection.Fraction, Event, Age)
desc_outer <- makeResampleDesc("Holdout", split = 3/4, stratify = TRUE)
final_task <- makeClassifTask(id = "HeartFailure", data = final_data, target = "Event", positive = 1)
set.seed(12345)
partition_outer <- makeResampleInstance(desc_outer, final_task)
prueba_learner <- makeLearner("classif.ranger", mtry=1, num.trees=625, min.node.size=35)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_task,
resampling = partition_outer,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
data_surv <- as.data.frame(data_surv_tot[train.idxs,]) %>% mutate_at(vars(Gender, Smoking, Diabetes, BP), as.numeric)
surv_task <- makeClassifTask(id = "HeartFailure", data = data_surv, target = "Event", positive = 1)
set.seed(12345)
desc_inner_surv <- makeResampleInstance("RepCV", reps = 5,  folds = 2, task = surv_task, stratify = TRUE)
desc_inner_surv
# learners, search space and control grid previously defined
parallelStartSocket(5)
set.seed(12345)
tuning_results_surv <- tuneParams(learner = lrn,
task = surv_task,
resampling = desc_inner_surv,
par.set = ps,
control = control_grid,
measures = list(acc, tpr),
show.info = FALSE)
parallelStop()
tuning_results_surv
View(tuning_results_surv)
fv2 <- generateFilterValuesData(surv_task, method = "FSelectorRcpp_information.gain")
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
# fv2$data[order(-value)]
data_surv_fs <- as.data.frame(data_surv) %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age)
surv_task_fs <- makeClassifTask(id = "HeartFailure", data = data_surv_fs, target = "Event", positive = 1)
set.seed(12345)
desc_inner_surv_fs <- makeResampleInstance("RepCV", reps = 5,  folds = 2, task = surv_task_fs, stratify = TRUE)
# learners, search space and control grid previously defined
parallelStartSocket(5)
set.seed(12345)
tuning_results_surv_fs <- tuneParams(learner = lrn,
task = surv_task_fs,
resampling = desc_inner_surv_fs,
par.set = ps,
control = control_grid,
measures = list(acc, tpr),
show.info = FALSE)
parallelStop()
tuning_results_surv_fs
?tuneParams
# Obtaining best iteration for each learner (selecting features)
res_iters_surv_fs <- getTuneResultOptPath(tuning_results_surv_fs)
best_res_surv <- res_iters_surv_fs %>% group_by(selected.learner) %>% slice(which.max(tpr.test.mean)) %>%
relocate(tpr.test.mean, .after = selected.learner)
temp2 <- melt(as.data.frame(best_res_surv)) %>% dplyr::select(-error.message) %>% drop_na()
tpr.test <- temp2 %>% filter(grepl("tpr", variable)) %>% dplyr::rename(tpr = value) %>% dplyr::select(-variable)
hyperparam <- temp2 %>% filter(grepl("classif", variable))
tuning_res_surv <- full_join(hyperparam, tpr.test) %>%
mutate(parameter = ifelse(grepl("\\.", variable), sub(".*\\.(.*)", "\\1", variable), "")) %>%
dplyr::select(selected.learner, tpr, parameter, value)
rm(temp2, tpr.test, hyperparam)
#tuning_res_surv
tuning_res_surv
final_data_surv <- data_surv_tot %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 1, ntree = 585, nodesize = 50)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
tuning_results_surv$y
tuning_results_surv$y[2]
tuning_results_surv_fs$y[2]
final_data_surv <- data_surv_tot %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 1, ntree = 585, nodesize = 50)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
final_data_surv <- data_surv_tot
#%>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 1, ntree = 585, nodesize = 50)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
final_data_surv <- data_surv_tot
#%>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 1, ntree = 344, nodesize = 34)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
final_data_surv <- data_surv_tot %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 1, ntree = 344, nodesize = 34)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
?biserial.cor
??biserial.cor
library(ltm)
?element_text
?theme
plotFilterValues(fv, feat.type.cols = TRUE) + scale_fill_brewer(palette="Blues") + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size = 5)) +
ggtitle("Filter Selection \n Information Gain")
plotFilterValues(fv, feat.type.cols = TRUE) + scale_fill_brewer(palette="Blues") + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size = 15)) +
ggtitle("Filter Selection \n Information Gain")
library(FSelectorRcpp)
fv <- generateFilterValuesData(fs_task, method = "FSelectorRcpp_information.gain")
plotFilterValues(fv, feat.type.cols = TRUE) + scale_fill_brewer(palette="Blues") + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size = 15)) +
ggtitle("Filter Selection \n Information Gain")
library(FSelectorRcpp)
fv <- generateFilterValuesData(fs_task, method = "FSelectorRcpp_information.gain")
plotFilterValues(fv, feat.type.cols = TRUE) + scale_fill_brewer(palette="Blues") + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size = 15)) +
ggtitle("Filter Selection \n Information Gain")
library(FSelectorRcpp)
fv <- generateFilterValuesData(fs_task, method = "FSelectorRcpp_information.gain")
plotFilterValues(fv, feat.type.cols = TRUE) + scale_fill_brewer(palette="Blues") + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size = 15),
legend="none") +
ggtitle("Filter Selection \n Information Gain")
plotFilterValues(fv, feat.type.cols = TRUE) + scale_fill_brewer(palette="Blues") + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size = 15)) +
ggtitle("Filter Selection \n Information Gain")
?ggtitle
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size=1)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=4),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=10),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=8),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=9),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
plotFilterValues(fv, feat.type.cols = TRUE) + scale_fill_brewer(palette="Blues") + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=9),
title = element_text(size = 15)) +
ggtitle("Filter Selection \n Information Gain")
?generateFilterValuesData
fv2 <- generateFilterValuesData(surv_task, method = "randomForestSRC_importance")
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=9),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
# fv2$data[order(-value)]
data_surv
data_surv_fs <- as.data.frame(data_surv) %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age, Age_Ejection.Fraction)
surv_task_fs <- makeClassifTask(id = "HeartFailure", data = data_surv_fs, target = "Event", positive = 1)
set.seed(12345)
desc_inner_surv_fs <- makeResampleInstance("RepCV", reps = 5,  folds = 2, task = surv_task_fs, stratify = TRUE)
# Obtaining best iteration for each learner (selecting features)
res_iters_surv_fs <- getTuneResultOptPath(tuning_results_surv_fs)
best_res_surv <- res_iters_surv_fs %>% group_by(selected.learner) %>% slice(which.max(tpr.test.mean)) %>%
relocate(tpr.test.mean, .after = selected.learner)
temp2 <- melt(as.data.frame(best_res_surv)) %>% dplyr::select(-error.message) %>% drop_na()
tpr.test <- temp2 %>% filter(grepl("tpr", variable)) %>% dplyr::rename(tpr = value) %>% dplyr::select(-variable)
hyperparam <- temp2 %>% filter(grepl("classif", variable))
tuning_res_surv <- full_join(hyperparam, tpr.test) %>%
mutate(parameter = ifelse(grepl("\\.", variable), sub(".*\\.(.*)", "\\1", variable), "")) %>%
dplyr::select(selected.learner, tpr, parameter, value)
rm(temp2, tpr.test, hyperparam)
#tuning_res_surv
final_data_surv <- data_surv_tot %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age, Age_Ejection.Fraction)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 1, ntree = 344, nodesize = 34)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
data_surv
fv2 <- generateFilterValuesData(surv_task, method = "FSelectorRcpp_information.gain")
data_surv <- as.data.frame(data_surv_tot[train.idxs,]) %>% mutate_at(vars(Gender, Smoking, Diabetes, BP), as.numeric)
surv_task <- makeClassifTask(id = "HeartFailure", data = data_surv, target = "Event", positive = 1)
set.seed(12345)
desc_inner_surv <- makeResampleInstance("RepCV", reps = 5,  folds = 2, task = surv_task, stratify = TRUE)
fv2 <- generateFilterValuesData(surv_task, method = "FSelectorRcpp_information.gain")
# FSelectorRcpp_information.gain
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=9),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
# fv2$data[order(-value)]
fv2 <- generateFilterValuesData(surv_task, method = "randomForestSRC_importance")
# FSelectorRcpp_information.gain
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=9),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
# fv2$data[order(-value)]
data_surv
data_surv_fs <- as.data.frame(data_surv) %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age, Ejection.Fraction_Creatinine)
surv_task_fs <- makeClassifTask(id = "HeartFailure", data = data_surv_fs, target = "Event", positive = 1)
set.seed(12345)
desc_inner_surv_fs <- makeResampleInstance("RepCV", reps = 5,  folds = 2, task = surv_task_fs, stratify = TRUE)
# learners, search space and control grid previously defined
parallelStartSocket(5)
set.seed(12345)
tuning_results_surv_fs <- tuneParams(learner = lrn,
task = surv_task_fs,
resampling = desc_inner_surv_fs,
par.set = ps,
control = control_grid,
measures = list(acc, tpr),
show.info = FALSE)
parallelStop()
# Obtaining best iteration for each learner (selecting features)
res_iters_surv_fs <- getTuneResultOptPath(tuning_results_surv_fs)
best_res_surv <- res_iters_surv_fs %>% group_by(selected.learner) %>% slice(which.max(tpr.test.mean)) %>%
relocate(tpr.test.mean, .after = selected.learner)
temp2 <- melt(as.data.frame(best_res_surv)) %>% dplyr::select(-error.message) %>% drop_na()
tpr.test <- temp2 %>% filter(grepl("tpr", variable)) %>% dplyr::rename(tpr = value) %>% dplyr::select(-variable)
hyperparam <- temp2 %>% filter(grepl("classif", variable))
tuning_res_surv <- full_join(hyperparam, tpr.test) %>%
mutate(parameter = ifelse(grepl("\\.", variable), sub(".*\\.(.*)", "\\1", variable), "")) %>%
dplyr::select(selected.learner, tpr, parameter, value)
rm(temp2, tpr.test, hyperparam)
#tuning_res_surv
# Obtaining best iteration for each learner (selecting features)
res_iters_surv_fs <- getTuneResultOptPath(tuning_results_surv_fs)
best_res_surv <- res_iters_surv_fs %>% group_by(selected.learner) %>% slice(which.max(tpr.test.mean)) %>%
relocate(tpr.test.mean, .after = selected.learner)
temp2 <- melt(as.data.frame(best_res_surv)) %>% dplyr::select(-error.message) %>% drop_na()
tpr.test <- temp2 %>% filter(grepl("tpr", variable)) %>% dplyr::rename(tpr = value) %>% dplyr::select(-variable)
hyperparam <- temp2 %>% filter(grepl("classif", variable))
tuning_res_surv <- full_join(hyperparam, tpr.test) %>%
mutate(parameter = ifelse(grepl("\\.", variable), sub(".*\\.(.*)", "\\1", variable), "")) %>%
dplyr::select(selected.learner, tpr, parameter, value)
rm(temp2, tpr.test, hyperparam)
#tuning_res_surv
final_data_surv <- data_surv_tot %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age, Ejection.Fraction_Creatinine)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 1, ntree = 344, nodesize = 34)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
tuning_res_surv
tuning_results_surv_fs
final_data_surv <- data_surv_tot %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age, Ejection.Fraction_Creatinine)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 1, ntree = 305, nodesize = 26)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
final_data_surv <- data_surv_tot %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age, Ejection.Fraction_Creatinine)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 2, ntree = 305, nodesize = 26)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
fv2 <- generateFilterValuesData(surv_task, method = "FSelectorRcpp_information.gain")
#  randomForestSRC_importance
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=9),
title = element_text(size=15)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")
# fv2$data[order(-value)]
data_surv_fs <- as.data.frame(data_surv) %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age)
surv_task_fs <- makeClassifTask(id = "HeartFailure", data = data_surv_fs, target = "Event", positive = 1)
set.seed(12345)
desc_inner_surv_fs <- makeResampleInstance("RepCV", reps = 5,  folds = 2, task = surv_task_fs, stratify = TRUE)
# learners, search space and control grid previously defined
parallelStartSocket(5)
set.seed(12345)
tuning_results_surv_fs <- tuneParams(learner = lrn,
task = surv_task_fs,
resampling = desc_inner_surv_fs,
par.set = ps,
control = control_grid,
measures = list(acc, tpr),
show.info = FALSE)
parallelStop()
# Obtaining best iteration for each learner (selecting features)
res_iters_surv_fs <- getTuneResultOptPath(tuning_results_surv_fs)
best_res_surv <- res_iters_surv_fs %>% group_by(selected.learner) %>% slice(which.max(tpr.test.mean)) %>%
relocate(tpr.test.mean, .after = selected.learner)
temp2 <- melt(as.data.frame(best_res_surv)) %>% dplyr::select(-error.message) %>% drop_na()
tpr.test <- temp2 %>% filter(grepl("tpr", variable)) %>% dplyr::rename(tpr = value) %>% dplyr::select(-variable)
hyperparam <- temp2 %>% filter(grepl("classif", variable))
tuning_res_surv <- full_join(hyperparam, tpr.test) %>%
mutate(parameter = ifelse(grepl("\\.", variable), sub(".*\\.(.*)", "\\1", variable), "")) %>%
dplyr::select(selected.learner, tpr, parameter, value)
rm(temp2, tpr.test, hyperparam)
#tuning_res_surv
tuning_results_surv_fs
final_data_surv <- data_surv_tot %>% dplyr::select(Event, Creatinine, Ejection.Fraction, Ejection.Fraction_Diabetes, Age)
final_surv_task <- makeClassifTask(id = "HeartFailure", data = final_data_surv, target = "Event", positive = 1)
set.seed(12345)
partition_outer_surv <- makeResampleInstance(desc_outer, final_surv_task)
# prueba_learner <- makeLearner("classif.rpart", minsplit = 21, maxdepth = 5)
# prueba_learner <- makeLearner("classif.ranger", mtry = 2, num.trees = 1230, min.node.size = 39)
prueba_learner <- makeLearner("classif.randomForest", mtry = 2, ntree = 344, nodesize = 34)
set.seed(12345)
prueba_results <- resample(learner = prueba_learner,
task = final_surv_task,
resampling = partition_outer_surv,
measures = list(tpr),
models = TRUE,
show.info = TRUE)
#  randomForestSRC_importance
plotFilterValues(fv2, feat.type.cols = TRUE) + ggpubr::theme_pubr() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=9),
title = element_text(size=10)) +
ggtitle("Filter Selection \n Information Gain") + scale_fill_brewer(palette="Blues")

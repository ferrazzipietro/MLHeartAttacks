<<<<<<< HEAD
data_classif <- data %>% dplyr::select(Creatinine, Ejection.Fraction, Event)
classif_task <- makeClassifTask(id = "HeartFailure", data = data_classif, target = "Event", positive = 1)
set.seed(1234)
desc_inner <- makeResampleInstance("RepCV", reps = 2,  folds = 4, task = classif_task)
# https://mlr.mlr-org.com/articles/tutorial/integrated_learners.html
classif_measures <- list(tpr, fnr, acc, auc, timetrain)
classif_pipeline <- cpoScaleRange()
## GLM ##
library(h2o)
classif_lrn_glm <- makeLearner("classif.h2o.glm", id = "glm", predict.type = "prob")
classif_lrn_glm <- classif_pipeline %>>% classif_lrn_glm
## Naive Bayes ##
classif_lrn_naive <- makeLearner("classif.naiveBayes", id = "naive", predict.type = "prob")
classif_lrn_naive <- classif_pipeline %>>% classif_lrn_naive
## KNN Model ##
library(kknn)
classif_lrn_knn <- makeLearner("classif.kknn", id = "knn", predict.type = "prob")
classif_lrn_knn <- classif_pipeline %>>% classif_lrn_knn
## LDA ##
library(MASS)
classif_lrn_lda <- makeLearner("classif.lda", id = "LDA", predict.type = "prob")
classif_lrn_lda <- classif_pipeline %>>% classif_lrn_lda
## QDA ##
classif_lrn_qda <- makeLearner("classif.qda", id = "QDA", predict.type = "prob")
classif_lrn_qda <- classif_pipeline %>>% classif_lrn_qda
## Tree(rpart) ##
classif_lrn_rpart <- makeLearner("classif.rpart", id = "rpart", predict.type = "prob")
classif_lrn_rpart <- classif_pipeline %>>% classif_lrn_rpart
## Random Forest ##
classif_lrn_rf <- makeLearner("classif.randomForest", id = "rf", predict.type = "prob")
classif_lrn_rf <- classif_pipeline %>>% classif_lrn_rf
## Ranger ##
classif_lrn_ranger <- makeLearner("classif.ranger", id = "ranger", predict.type = "prob")
classif_lrn_ranger <- classif_pipeline %>>% classif_lrn_ranger
## SVM ##
classif_lrn_SVM <- makeLearner("classif.svm", id = "SVM", predict.type = "prob")
classif_lrn_SVM <- classif_pipeline %>>% classif_lrn_SVM
## Ada Boosting ##
library(ada)
classif_lrn_ada <- makeLearner("classif.ada", id = "ada", predict.type = "prob")
classif_lrn_ada <- classif_pipeline %>>% classif_lrn_ada
## Neural Net ##
# library(neuralnet)
classif_lrn_neuralnet <- makeLearner("classif.neuralnet", id = "neuralnet", predict.type = "prob")
classif_lrn_neuralnet <- classif_pipeline %>>% classif_lrn_neuralnet
## Extreme Gradient Boosting ##
classif_lrn_xgboost <- makeLearner("classif.xgboost", id = "xgboost", predict.type = "prob")
classif_lrn_xgboost <- classif_pipeline %>>% classif_lrn_xgboost
# Repeated cross-validation splits the data in k folds, n reps (folds will be different n times)
# This prevents from noisy estimates of model performance, because different splits may result in very different results. MENTION STRATIFICATION
# outer <- makeResampleDesc("RepCV", reps = 10,
#                           folds = 5, stratify = TRUE)
learners <- list(classif_lrn_glm, classif_lrn_naive, classif_lrn_knn, classif_lrn_lda, classif_lrn_qda,
classif_lrn_rpart, classif_lrn_rf, classif_lrn_ranger, classif_lrn_SVM, classif_lrn_ada,
classif_lrn_neuralnet, classif_lrn_xgboost)
library(parallelMap)
parallelStartSocket(2) # start in socket mode and create 2 processes on localhost
set.seed(1234)
bmr_classif <- benchmark(learners    = learners,
tasks       = classif_task,
resamplings = desc_inner,
measures    = classif_measures,
models      = TRUE,
show.info   = FALSE)
bmr_classif
parallelStop()
bp1 <- plotBMRBoxplots(bmr_classif,
measure   = tpr,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(color = learner.id)
bp2 <- plotBMRBoxplots(bmr_classif,
measure   = timetrain,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(color = learner.id)
ggarrange(bp1, bp2, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
data_classif <- data %>% dplyr::select(Creatinine, Ejection.Fraction, Event)
classif_task <- makeClassifTask(id = "HeartFailure", data = data_classif, target = "Event", positive = 1)
set.seed(123)
desc_inner <- makeResampleInstance("RepCV", reps = 2,  folds = 4, task = classif_task)
# https://mlr.mlr-org.com/articles/tutorial/integrated_learners.html
classif_measures <- list(tpr, fnr, acc, auc, timetrain)
classif_pipeline <- cpoScaleRange()
## GLM ##
library(h2o)
classif_lrn_glm <- makeLearner("classif.h2o.glm", id = "glm", predict.type = "prob")
classif_lrn_glm <- classif_pipeline %>>% classif_lrn_glm
## Naive Bayes ##
classif_lrn_naive <- makeLearner("classif.naiveBayes", id = "naive", predict.type = "prob")
classif_lrn_naive <- classif_pipeline %>>% classif_lrn_naive
## KNN Model ##
library(kknn)
classif_lrn_knn <- makeLearner("classif.kknn", id = "knn", predict.type = "prob")
classif_lrn_knn <- classif_pipeline %>>% classif_lrn_knn
## LDA ##
library(MASS)
classif_lrn_lda <- makeLearner("classif.lda", id = "LDA", predict.type = "prob")
classif_lrn_lda <- classif_pipeline %>>% classif_lrn_lda
## QDA ##
classif_lrn_qda <- makeLearner("classif.qda", id = "QDA", predict.type = "prob")
classif_lrn_qda <- classif_pipeline %>>% classif_lrn_qda
## Tree(rpart) ##
classif_lrn_rpart <- makeLearner("classif.rpart", id = "rpart", predict.type = "prob")
classif_lrn_rpart <- classif_pipeline %>>% classif_lrn_rpart
## Random Forest ##
classif_lrn_rf <- makeLearner("classif.randomForest", id = "rf", predict.type = "prob")
classif_lrn_rf <- classif_pipeline %>>% classif_lrn_rf
## Ranger ##
classif_lrn_ranger <- makeLearner("classif.ranger", id = "ranger", predict.type = "prob")
classif_lrn_ranger <- classif_pipeline %>>% classif_lrn_ranger
## SVM ##
classif_lrn_SVM <- makeLearner("classif.svm", id = "SVM", predict.type = "prob")
classif_lrn_SVM <- classif_pipeline %>>% classif_lrn_SVM
## Ada Boosting ##
library(ada)
classif_lrn_ada <- makeLearner("classif.ada", id = "ada", predict.type = "prob")
classif_lrn_ada <- classif_pipeline %>>% classif_lrn_ada
## Neural Net ##
# library(neuralnet)
classif_lrn_neuralnet <- makeLearner("classif.neuralnet", id = "neuralnet", predict.type = "prob")
classif_lrn_neuralnet <- classif_pipeline %>>% classif_lrn_neuralnet
## Extreme Gradient Boosting ##
classif_lrn_xgboost <- makeLearner("classif.xgboost", id = "xgboost", predict.type = "prob")
classif_lrn_xgboost <- classif_pipeline %>>% classif_lrn_xgboost
learners <- list(classif_lrn_glm, classif_lrn_naive, classif_lrn_knn, classif_lrn_lda, classif_lrn_qda,
classif_lrn_rpart, classif_lrn_rf, classif_lrn_ranger, classif_lrn_SVM, classif_lrn_ada,
classif_lrn_neuralnet, classif_lrn_xgboost)
library(parallelMap)
parallelStartSocket(2) # start in socket mode and create 2 processes on localhost
set.seed(123)
bmr_classif <- benchmark(learners    = learners,
tasks       = classif_task,
resamplings = desc_inner,
measures    = classif_measures,
models      = TRUE,
show.info   = FALSE)
bmr_classif
parallelStop()
bp1 <- plotBMRBoxplots(bmr_classif,
measure   = tpr,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(color = learner.id)
bp2 <- plotBMRBoxplots(bmr_classif,
measure   = timetrain,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(color = learner.id)
ggarrange(bp1, bp2, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
configureMlr(show.info = TRUE, on.learner.warning = "warn") # see all info
# configureMlr(show.info = FALSE, on.learner.warning = "quiet") # so we don't get too many messages
=======
scale_fill_brewer(palette="Blues") +
theme_minimal()
g2 <- g + geom_boxplot(aes(x=as_factor(Gender), fill=Gender)) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g3 <- g + geom_boxplot(aes(x=as_factor(Smoking), fill=Smoking)) +
labs(title="",x="", y = "", color="Smoking")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g4 <- g + geom_boxplot(aes(x=as_factor(Diabetes), fill=Diabetes)) +
labs(title="",x="", y = "", color="Diabetes")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g5 <- g + geom_boxplot(aes(x=as_factor(BP), fill=BP)) +
labs(title="",x="", y = "", color="BP")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g6 <- g + geom_boxplot(aes(x=as_factor(Anaemia), fill=Anaemia)) +
labs(title="",x="", y = "", color="Anaemia")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
ggarrange(g1,g2,g3,g4,g5,g6, ncol = 3, nrow = 2) %>%
annotate_figure(top=text_grob("Sodium", face="bold"))
g <- ggplot(data, aes(y=Sodium))
g1 <- g + geom_boxplot(aes(x=as_factor(Event), fll=Event)) +
labs(title="",x="", y = "", color="Event")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g1 <- g + geom_boxplot(aes(x=as_factor(Event), fill=Event)) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g2 <- g + geom_boxplot(aes(x=as_factor(Gender), fill=Gender)) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g3 <- g + geom_boxplot(aes(x=as_factor(Smoking), fill=Smoking)) +
labs(title="",x="", y = "", color="Smoking")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g4 <- g + geom_boxplot(aes(x=as_factor(Diabetes), fill=Diabetes)) +
labs(title="",x="", y = "", color="Diabetes")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g5 <- g + geom_boxplot(aes(x=as_factor(BP), fill=BP)) +
labs(title="",x="", y = "", color="BP")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g6 <- g + geom_boxplot(aes(x=as_factor(Anaemia), fill=Anaemia)) +
labs(title="",x="", y = "", color="Anaemia")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
ggarrange(g1,g2,g3,g4,g5,g6, ncol = 3, nrow = 2) %>%
annotate_figure(top=text_grob("Sodium", face="bold"))
g <- ggplot(data, aes(y=Pletelets))
g1 <- g + geom_boxplot(aes(x=as.factor(Event), color=as.factor(Event))) +
labs(title="",x="", y = "", color="Event")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g2 <- g + geom_boxplot(aes(x=as_factor(Gender), color=as.factor(Gender))) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g3 <- g + geom_boxplot(aes(x=as_factor(Smoking), color=as.factor(Smoking))) +
labs(title="",x="", y = "", color="Smoking")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g4 <- g + geom_boxplot(aes(x=as_factor(Diabetes), color=as.factor(Diabetes))) +
labs(title="",x="", y = "", color="Diabetes")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g5 <- g + geom_boxplot(aes(x=as_factor(BP), color=as.factor(BP))) +
labs(title="",x="", y = "", color="BP")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g6 <- g + geom_boxplot(aes(x=as_factor(Anaemia), color=as.factor(Anaemia))) +
labs(title="",x="", y = "", color="Anaemia")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
ggarrange(g1,g2,g3,g4,g5,g6, ncol = 3, nrow = 2) %>%
annotate_figure(top=text_grob("Pletelets", face="bold"))
g <- ggplot(data, aes(y=Pletelets))
g1 <- g + geom_boxplot(aes(x=as_factor(Event), fill=Event)) +
labs(title="",x="", y = "", color="Event")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g2 <- g + geom_boxplot(aes(x=as_factor(Gender), fill=Gender)) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g3 <- g + geom_boxplot(aes(x=as_factor(Smoking), fill=Smoking)) +
labs(title="",x="", y = "", color="Smoking")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g4 <- g + geom_boxplot(aes(x=as_factor(Diabetes), fill=Diabetes)) +
labs(title="",x="", y = "", color="Diabetes")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g5 <- g + geom_boxplot(aes(x=as_factor(BP), fill=BP)) +
labs(title="",x="", y = "", color="BP")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g6 <- g + geom_boxplot(aes(x=as_factor(Anaemia), fill=Anaemia)) +
labs(title="",x="", y = "", color="Anaemia")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
ggarrange(g1,g2,g3,g4,g5,g6, ncol = 3, nrow = 2) %>%
annotate_figure(top=text_grob("Pletelets", face="bold"))
data_for_creatinine <- data %>% dplyr::select(Creatinine)
idxLessThan5 <- data_for_creatinine$Creatinine<5
LessThan5 <- data_for_creatinine$Creatinine
LessThan5[! idxLessThan5]=NA
data_for_creatinine <- data_for_creatinine %>% add_column( LessThan5 = LessThan5)
ggplot(data_for_creatinine) + stat_density(aes(Creatinine), adjust = 2, alpha=1, col=1,geom="line") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold")) +
stat_density(aes(data_for_creatinine$LessThan5), adjust = 2, alpha=1, fill=2, col=2,geom="line")
g <- ggplot(data %>% filter(Creatinine<5), aes(y=Creatinine))
g1 <- g + geom_boxplot(aes(x=as.factor(Event), color=as.factor(Event)), coef=2.5) +
labs(title="",x="", y = "", color="Event")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g2 <- g + geom_boxplot(aes(x=as_factor(Gender), color=as.factor(Gender)), coef=2.5) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g3 <- g + geom_boxplot(aes(x=as_factor(Smoking), color=as.factor(Smoking)), coef=2.5) +
labs(title="",x="", y = "", color="Smoking")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g4 <- g + geom_boxplot(aes(x=as_factor(Diabetes), color=as.factor(Diabetes)), coef=2.5) +
labs(title="",x="", y = "", color="Diabetes")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g5 <- g + geom_boxplot(aes(x=as_factor(BP), color=as.factor(BP)), coef=2.5) +
labs(title="",x="", y = "", color="BP")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g6 <- g + geom_boxplot(aes(x=as_factor(Anaemia), color=as.factor(Anaemia)), coef=2.5) +
labs(title="",x="", y = "", color="Anaemia")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
ggarrange(g1,g2,g3,g4,g5,g6,
ncol = 3, nrow = 2) %>% annotate_figure(top=text_grob("Creatinine",
face="bold"))
g <- ggplot(data %>% filter(Creatinine<5), aes(y=Creatinine))
g1 <- g + geom_boxplot(aes(x=as_factor(Event), fill=Event), coef=2.5) +
labs(title="",x="", y = "", color="Event")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g2 <- g + geom_boxplot(aes(x=as_factor(Gender), fill=Gender), coef=2.5) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g3 <- g + geom_boxplot(aes(x=as_factor(Smoking), fill=Smoking), coef=2.5) +
labs(title="",x="", y = "", color="Smoking")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g4 <- g + geom_boxplot(aes(x=as_factor(Diabetes), fill=Diabetes), coef=2.5) +
labs(title="",x="", y = "", color="Diabetes")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g5 <- g + geom_boxplot(aes(x=as_factor(BP), fill=BP), coef=2.5) +
labs(title="",x="", y = "", color="BP")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g6 <- g + geom_boxplot(aes(x=as_factor(Anaemia), fill=Anaemia), coef=2.5) +
labs(title="",x="", y = "", color="Anaemia")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
ggarrange(g1,g2,g3,g4,g5,g6,
ncol = 3, nrow = 2) %>% annotate_figure(top=text_grob("Creatinine",
face="bold"))
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8) +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8) +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="blues") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="blue") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="bluette") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="13") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="#000800") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="#000888") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="8FD6FA") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="8EC3E8") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="#8EC3E8") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))+
scale_fill_brewer(palette="Blues")
ggplot(data) + stat_density(aes(CPK), adjust = 2,
alpha=0.8, fill="#8EC3E8") +
theme_minimal() + labs(y="Density") +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=13,face="bold"),
legend.title =element_text(size=13,face="bold") ,
legend.text =element_text(size=12,face="bold"))
g <- ggplot(data %>% filter(CPK<4000), aes(y=CPK))
g1 <- g + geom_boxplot(aes(x=Event), color=Event)) +
g <- ggplot(data %>% filter(CPK<4000), aes(y=CPK))
g1 <- g + geom_boxplot(aes(x=as_factor(Event), color=Event)) +
labs(title="",x="", y = "", color="Event")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g2 <- g + geom_boxplot(aes(x=as_factor(Gender), fill=Gender)) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g3 <- g + geom_boxplot(aes(x=as_factor(Smoking), fill=Smoking)) +
labs(title="",x="", y = "", color="Smoking")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g4 <- g + geom_boxplot(aes(x=as_factor(Diabetes), fill=Diabetes)) +
labs(title="",x="", y = "", color="Diabetes")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g5 <- g + geom_boxplot(aes(x=as_factor(BP), fill=BP)) +
labs(title="",x="", y = "", color="BP")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g6 <- g + geom_boxplot(aes(x=as_factor(Anaemia), fill=Anaemia)) +
labs(title="",x="", y = "", color="Anaemia")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
ggarrange(g1,g2,g3,g4,g5,g6,
ncol = 3, nrow = 2) %>% annotate_figure(top=text_grob("CPK", face="bold"))
g <- ggplot(data %>% filter(CPK<4000), aes(y=CPK))
g1 <- g + geom_boxplot(aes(x=as_factor(Event), fill=Event)) +
labs(title="",x="", y = "", color="Event")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g2 <- g + geom_boxplot(aes(x=as_factor(Gender), fill=Gender)) +
labs(title="",x="", y = "", color="Gender")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g3 <- g + geom_boxplot(aes(x=as_factor(Smoking), fill=Smoking)) +
labs(title="",x="", y = "", color="Smoking")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g4 <- g + geom_boxplot(aes(x=as_factor(Diabetes), fill=Diabetes)) +
labs(title="",x="", y = "", color="Diabetes")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g5 <- g + geom_boxplot(aes(x=as_factor(BP), fill=BP)) +
labs(title="",x="", y = "", color="BP")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
g6 <- g + geom_boxplot(aes(x=as_factor(Anaemia), fill=Anaemia)) +
labs(title="",x="", y = "", color="Anaemia")  +
scale_fill_brewer(palette="Blues") +
theme_minimal()
ggarrange(g1,g2,g3,g4,g5,g6,
ncol = 3, nrow = 2) %>% annotate_figure(top=text_grob("CPK", face="bold"))
col <- scale_color_gradient(high=1, low = 0,
n.breaks=4,
breaks = waiver())
g <- ggplot(data, aes(col=Event))
g1 <- g + geom_point(aes(x=Sodium, y=Age),lwd=1)
g2 <- g + geom_point(aes(x=Sodium,  y=Creatinine),lwd=1)
g3 <- g + geom_point(aes(x=Sodium, y=CPK),lwd=1)
g4 <- g + geom_point(aes(x=Sodium, y=Pletelets),lwd=1)
g5 <- g + geom_point(aes(x=Sodium, y=Ejection.Fraction),lwd=1)
g6 <- g + geom_point(aes(x=CPK, y=Age),lwd=1)
g7 <- g + geom_point(aes(x=CPK, y=Creatinine),lwd=1)
g8 <- g + geom_point(aes(x=CPK, y=Pletelets),lwd=1)
g9 <- g + geom_point(aes(x=CPK, y=Ejection.Fraction),lwd=1)
g10 <- g + geom_point(aes(x=Pletelets, y=Creatinine),lwd=1)
g11 <- g + geom_point(aes(x=Pletelets, y=Age),lwd=1)
g12 <- g + geom_point(aes(x=Pletelets, y=Ejection.Fraction),lwd=1)
g13 <- g + geom_point(aes(x=Age, y=CPK), lwd=1)
g14 <- g + geom_point(aes(x=Age, y=Ejection.Fraction), lwd=1)
g15 <- g + geom_point(aes(x=CPK, y=Ejection.Fraction), lwd=1)
ggarrange(g1,g2,g3,g4,g5,g6,g7,g8,g9,g10,g11,g12,g13,g14,g15,
ncol = 3, nrow = 5, common.legend = TRUE) %>%
annotate_figure(top=text_grob("Distribution of events over pairs of var", face="bold"))
eventYN <- as.factor(data$Event)
levels(eventYN)<- c("Yes", "No")
pGender <- prop.table(table(Event=eventYN, Gender = data$Gender),2)
pSmoke <- prop.table(table(Event=eventYN, smoking=data$Smoking),2)
pDiab <- prop.table(table(Event=eventYN, Diabetes=data$Diabetes),2)
pBP <- prop.table(table(Event=eventYN, BP=data$BP),2)
pAnaemia <- prop.table(table(Event=eventYN, Anaemia=data$Anaemia),2)
barplot( pGender[,1])
barplot( pGender[,2])
heatmap(pSmoke)
heatmap(pDiab)
image(pBP)
m <- matrix(c(1,0.5,0.5,0.5), ncol=2)
image(m)
heatmap(pSmoke)
image(pBP)
?image
s1 <- Surv(data$TIME, data$Event)
surv_m1 <- survfit(s1~data$Gender, error="greenwood",
conf.type="log", se.fit=TRUE, conf.int=0.95,
data=data)
par(mfrow=c(3,2))
g <- list()
Evento <- as.numeric(levels(as.factor(data$Event)))[as.factor(data$Event)]
data$Evento=Evento
g[[1]] <- ggsurvplot(survfit(Surv(TIME, (Evento))~Gender, data=data),
conf.int=T, pval.method=T, log.rank.weights="1", data=data)
g[[2]] <- ggsurvplot(survfit(Surv(TIME, (Evento))~Smoking, data=data),
conf.int=T, pval.method=T, log.rank.weights="1", data=data)
g[[3]] <- ggsurvplot(survfit(Surv(TIME, (Evento))~Diabetes, data=data),
conf.int=T, pval.method=T, log.rank.weights="1", data=data)
g[[4]] <- ggsurvplot(survfit(Surv(TIME, (Evento))~BP, data=data),
conf.int=T, pval.method=T, log.rank.weights="1", data=data)
g[[5]] <- ggsurvplot(survfit(Surv(TIME, (Evento))~Anaemia, data=data),
conf.int=T, pval.method=T, log.rank.weights="1", data=data)
# g1
# g2
# g3
# g4
# g5
arrange_ggsurvplots(g, print = TRUE,
ncol = 2, nrow = 3, risk.table.height = 0.4)
# ggarrange(g1,g2,g3,g4,g5,
#           ncol = 2, nrow = 3) %>%
#   annotate_figure(top=text_grob("Distribution of events over pairs of var",
#                                 face="bold"))
ss <- survdiff(Surv(TIME, Evento)~Gender+Smoking+Diabetes+BP+Anaemia, data=data, rho=0)
# ggsurvplot(surv_fit(Surv(TIME, Evento)~Gender+Smoking+Diabetes+BP+Anaemia, data=data))
df <- nrow(ss$var)-1
>>>>>>> f1e40a6bcd8488a5a815c3f8039a1cd002eedba1
bls <- list(makeLearner("classif.kknn"),
makeLearner("classif.rpart"),
makeLearner("classif.randomForest"),
makeLearner("classif.ranger"),
makeLearner("classif.svm"),
makeLearner("classif.ada"),
<<<<<<< HEAD
makeLearner("classif.xgboost"),
makeLearner("classif.neuralnet"))
=======
makeLearner("classif.xgboost")
#            ,makeLearner("classif.neuralnet")
)
>>>>>>> f1e40a6bcd8488a5a815c3f8039a1cd002eedba1
lrn <- makeModelMultiplexer(bls)
# Parameter Space (all together, divided by learner inside)
ps <- makeModelMultiplexerParamSet(
multiplexer = lrn,
classif.kknn = makeParamSet(makeIntegerParam("k", lower = 5, upper = 15)), # Default is 7-
classif.rpart = makeParamSet(makeIntegerParam("minsplit", lower = 15, upper = 35), # Default is 20
makeIntegerParam("maxdepth", lower = 5, upper = 15)), # Default is 30
classif.randomForest = makeParamSet(makeIntegerParam("ntree", lower = 100, upper = 1500), #Default is 500
makeIntegerParam("mtry",lower = 1, upper = 2), #Default is floor(sqrt(features/3)), cannot be larger than number of variables
makeIntegerParam("nodesize", lower = 10, upper = 50)), #Default is 1
classif.ranger = makeParamSet(makeIntegerParam("mtry", lower = 1, upper = 2), # Same parameters as randomForest
makeIntegerParam("num.trees", lower = 100, upper = 1500),
makeIntegerParam("min.node.size", lower = 10, upper = 50)),
classif.svm = makeParamSet(makeNumericParam("cost", lower = 0.1, upper = 10), # Default is 1
makeNumericParam("gamma", lower = 0.05, upper = 5)), # Default is (1/data dimension)
classif.ada = makeParamSet(makeNumericParam("nu", lower = 0.05, upper = 3), # Default 0.1
makeIntegerParam("iter", lower = 20, upper = 200)), # Default is 50
classif.xgboost = makeParamSet(makeNumericParam("eta", lower = 0.2, upper = 0.5), # Default is 0.3
makeIntegerParam("nrounds", lower = 4, upper = 10), # Default is
makeIntegerParam("max_depth", lower = 3, upper = 10)), # Default is 6
<<<<<<< HEAD
classif.neuralnet = makeParamSet(makeIntegerVectorParam("hidden", len = 1, lower = 5, upper = 10),
makeNumericParam("threshold", lower = 2, upper = 5, trafo = function(x) {10^x}),
makeNumericParam("stepmax", lower = 2, upper = 2, trafo = function(x) {10^x}))
)
# Validation
desc_tuning <- makeResampleDesc("CV", iters = 4)
control_grid <- makeTuneControlRandom(maxit = 200L) # Default is 100, split between the amount of learners
set.seed(123)
tuning <- makeTuneWrapper(learner = lrn,
resampling = desc_tuning,
par.set = ps,
control = control_grid,
=======
#   classif.neuralnet = makeParamSet(makeIntegerVectorParam("hidden", len = 1, lower = 5, upper = 10),
#                                    makeNumericParam("threshold", lower = 2, upper = 5, trafo = function(x) {10^x}),
#                                    makeNumericParam("stepmax", lower = 2, upper = 2, trafo = function(x) {10^x}))
)
lrn
bls <- list(makeLearner("classif.kknn"),
makeLearner("classif.rpart"),
makeLearner("classif.randomForest"),
makeLearner("classif.ranger"),
makeLearner("classif.svm"),
makeLearner("classif.ada"),
makeLearner("classif.xgboost")
#            ,makeLearner("classif.neuralnet")
)
bls
lrn <- makeModelMultiplexer(bls)
# Parameter Space (all together, divided by learner inside)
ps <- makeModelMultiplexerParamSet(
multiplexer = lrn,
classif.kknn = makeParamSet(makeIntegerParam("k", lower = 5, upper = 15)), # Default is 7-
classif.rpart = makeParamSet(makeIntegerParam("minsplit", lower = 15, upper = 35), # Default is 20
makeIntegerParam("maxdepth", lower = 5, upper = 15)), # Default is 30
classif.randomForest = makeParamSet(makeIntegerParam("ntree", lower = 100, upper = 1500), #Default is 500
makeIntegerParam("mtry",lower = 1, upper = 2), #Default is floor(sqrt(features/3)), cannot be larger than number of variables
makeIntegerParam("nodesize", lower = 10, upper = 50)), #Default is 1
classif.ranger = makeParamSet(makeIntegerParam("mtry", lower = 1, upper = 2), # Same parameters as randomForest
makeIntegerParam("num.trees", lower = 100, upper = 1500),
makeIntegerParam("min.node.size", lower = 10, upper = 50)),
classif.svm = makeParamSet(makeNumericParam("cost", lower = 0.1, upper = 10), # Default is 1
makeNumericParam("gamma", lower = 0.05, upper = 5)), # Default is (1/data dimension)
classif.ada = makeParamSet(makeNumericParam("nu", lower = 0.05, upper = 3), # Default 0.1
makeIntegerParam("iter", lower = 20, upper = 200)), # Default is 50
classif.xgboost = makeParamSet(makeNumericParam("eta", lower = 0.2, upper = 0.5), # Default is 0.3
makeIntegerParam("nrounds", lower = 4, upper = 10), # Default is
makeIntegerParam("max_depth", lower = 3, upper = 10)), # Default is 6
#   classif.neuralnet = makeParamSet(makeIntegerVectorParam("hidden", len = 1, lower = 5, upper = 10),
#                                    makeNumericParam("threshold", lower = 2, upper = 5, trafo = function(x) {10^x}),
#                                    makeNumericParam("stepmax", lower = 2, upper = 2, trafo = function(x) {10^x}))
)
bls <- list(makeLearner("classif.kknn"),
makeLearner("classif.rpart"),
makeLearner("classif.randomForest"),
makeLearner("classif.ranger"),
makeLearner("classif.svm"),
makeLearner("classif.ada"),
makeLearner("classif.xgboost")
,makeLearner("classif.neuralnet")
)
# Parameter Space (all together, divided by learner inside)
ps <- makeModelMultiplexerParamSet(
multiplexer = lrn,
classif.kknn = makeParamSet(makeIntegerParam("k", lower = 5, upper = 15)), # Default is 7-
classif.rpart = makeParamSet(makeIntegerParam("minsplit", lower = 15, upper = 35), # Default is 20
makeIntegerParam("maxdepth", lower = 5, upper = 15)), # Default is 30
classif.randomForest = makeParamSet(makeIntegerParam("ntree", lower = 100, upper = 1500), #Default is 500
makeIntegerParam("mtry",lower = 1, upper = 2), #Default is floor(sqrt(features/3)), cannot be larger than number of variables
makeIntegerParam("nodesize", lower = 10, upper = 50)), #Default is 1
classif.ranger = makeParamSet(makeIntegerParam("mtry", lower = 1, upper = 2), # Same parameters as randomForest
makeIntegerParam("num.trees", lower = 100, upper = 1500),
makeIntegerParam("min.node.size", lower = 10, upper = 50)),
classif.svm = makeParamSet(makeNumericParam("cost", lower = 0.1, upper = 10), # Default is 1
makeNumericParam("gamma", lower = 0.05, upper = 5)), # Default is (1/data dimension)
classif.ada = makeParamSet(makeNumericParam("nu", lower = 0.05, upper = 3), # Default 0.1
makeIntegerParam("iter", lower = 20, upper = 200)), # Default is 50
classif.xgboost = makeParamSet(makeNumericParam("eta", lower = 0.2, upper = 0.5), # Default is 0.3
makeIntegerParam("nrounds", lower = 4, upper = 10), # Default is
makeIntegerParam("max_depth", lower = 3, upper = 10)), # Default is 6
#   classif.neuralnet = makeParamSet(makeIntegerVectorParam("hidden", len = 1, lower = 5, upper = 10),
#                                    makeNumericParam("threshold", lower = 2, upper = 5, trafo = function(x) {10^x}),
#                                    makeNumericParam("stepmax", lower = 2, upper = 2, trafo = function(x) {10^x}))
)
?makeModelMultiplexerParamSet
# Parallelize model evaluation (it takes pretty long)
parallelStartSocket(5) # start in socket mode and create 2 processes on localhost
set.seed(1234)
results <- mlr::resample(learner = tuning,
task = classif_task,
resampling = desc_inner,
>>>>>>> f1e40a6bcd8488a5a815c3f8039a1cd002eedba1
measures = list(tpr),
models = TRUE,
extract = getTuneResult,
show.info = TRUE)
<<<<<<< HEAD
# Parallelize model evaluation (it takes pretty long)
#parallelStartSocket(5) # start in socket mode and create 2 processes on localhost
set.seed(123)
results <- mlr::resample(learner = tuning,
task = classif_task,
resampling = desc_inner,
measures = list(tpr),
models = TRUE,
extract = getTuneResult,
show.info = TRUE)
parallelStop()
res_iters <- getNestedTuneResultsOptPathDf(results)
?xgboost
bls <- list(makeLearner("classif.kknn"),
makeLearner("classif.rpart"),
makeLearner("classif.randomForest"),
makeLearner("classif.ranger"),
makeLearner("classif.svm"),
makeLearner("classif.ada"),
makeLearner("classif.xgboost", eval_metric = "aucpr"),
makeLearner("classif.neuralnet"))
lrn <- makeModelMultiplexer(bls)
# Parameter Space (all together, divided by learner inside)
ps <- makeModelMultiplexerParamSet(
multiplexer = lrn,
classif.kknn = makeParamSet(makeIntegerParam("k", lower = 5, upper = 15)), # Default is 7-
classif.rpart = makeParamSet(makeIntegerParam("minsplit", lower = 15, upper = 35), # Default is 20
makeIntegerParam("maxdepth", lower = 5, upper = 15)), # Default is 30
classif.randomForest = makeParamSet(makeIntegerParam("ntree", lower = 100, upper = 1500), #Default is 500
makeIntegerParam("mtry",lower = 1, upper = 2), #Default is floor(sqrt(features/3)), cannot be larger than number of variables
makeIntegerParam("nodesize", lower = 10, upper = 50)), #Default is 1
classif.ranger = makeParamSet(makeIntegerParam("mtry", lower = 1, upper = 2), # Same parameters as randomForest
makeIntegerParam("num.trees", lower = 100, upper = 1500),
makeIntegerParam("min.node.size", lower = 10, upper = 50)),
classif.svm = makeParamSet(makeNumericParam("cost", lower = 0.1, upper = 10), # Default is 1
makeNumericParam("gamma", lower = 0.05, upper = 5)), # Default is (1/data dimension)
classif.ada = makeParamSet(makeNumericParam("nu", lower = 0.05, upper = 3), # Default 0.1
makeIntegerParam("iter", lower = 20, upper = 200)), # Default is 50
classif.xgboost = makeParamSet(makeNumericParam("eta", lower = 0.2, upper = 0.5), # Default is 0.3
makeIntegerParam("nrounds", lower = 4, upper = 10), # Default is
makeIntegerParam("max_depth", lower = 3, upper = 10)), # Default is 6
classif.neuralnet = makeParamSet(makeIntegerVectorParam("hidden", len = 1, lower = 5, upper = 10),
makeNumericParam("threshold", lower = 2, upper = 5, trafo = function(x) {10^x}),
makeNumericParam("stepmax", lower = 2, upper = 2, trafo = function(x) {10^x}))
)
# Validation
desc_tuning <- makeResampleDesc("CV", iters = 4)
control_grid <- makeTuneControlRandom(maxit = 200L) # Default is 100, split between the amount of learners
set.seed(123)
tuning <- makeTuneWrapper(learner = lrn,
resampling = desc_tuning,
par.set = ps,
control = control_grid,
measures = list(tpr),
show.info = TRUE)
# Parallelize model evaluation (it takes pretty long)
#parallelStartSocket(5) # start in socket mode and create 2 processes on localhost
set.seed(123)
results <- mlr::resample(learner = tuning,
task = classif_task,
resampling = desc_inner,
measures = list(tpr),
models = TRUE,
extract = getTuneResult,
show.info = TRUE)
parallelStop()
res_iters <- getNestedTuneResultsOptPathDf(results)
parallelStop()
# Parallelize model evaluation (it takes pretty long)
parallelStartSocket(5) # start in socket mode and create 2 processes on localhost
set.seed(123)
results <- mlr::resample(learner = tuning,
task = classif_task,
resampling = desc_inner,
measures = list(tpr),
models = TRUE,
extract = getTuneResult,
show.info = TRUE)
bls <- list(makeLearner("classif.kknn"),
makeLearner("classif.rpart"),
makeLearner("classif.randomForest"),
makeLearner("classif.ranger"),
makeLearner("classif.svm"),
makeLearner("classif.ada"),
makeLearner("classif.xgboost", eval_metric = "aucpr"),
makeLearner("classif.neuralnet"))
lrn <- makeModelMultiplexer(bls)
# Parameter Space (all together, divided by learner inside)
ps <- makeModelMultiplexerParamSet(
multiplexer = lrn,
classif.kknn = makeParamSet(makeIntegerParam("k", lower = 5, upper = 15)), # Default is 7-
classif.rpart = makeParamSet(makeIntegerParam("minsplit", lower = 15, upper = 35), # Default is 20
makeIntegerParam("maxdepth", lower = 5, upper = 15)), # Default is 30
classif.randomForest = makeParamSet(makeIntegerParam("ntree", lower = 100, upper = 1500), #Default is 500
makeIntegerParam("mtry",lower = 1, upper = 2), #Default is floor(sqrt(features/3)), cannot be larger than number of variables
makeIntegerParam("nodesize", lower = 10, upper = 50)), #Default is 1
classif.ranger = makeParamSet(makeIntegerParam("mtry", lower = 1, upper = 2), # Same parameters as randomForest
makeIntegerParam("num.trees", lower = 100, upper = 1500),
makeIntegerParam("min.node.size", lower = 10, upper = 50)),
classif.svm = makeParamSet(makeNumericParam("cost", lower = 0.1, upper = 10), # Default is 1
makeNumericParam("gamma", lower = 0.05, upper = 5)), # Default is (1/data dimension)
classif.ada = makeParamSet(makeNumericParam("nu", lower = 0.05, upper = 3), # Default 0.1
makeIntegerParam("iter", lower = 20, upper = 200)), # Default is 50
classif.xgboost = makeParamSet(makeNumericParam("eta", lower = 0.2, upper = 0.5), # Default is 0.3
makeIntegerParam("nrounds", lower = 4, upper = 10), # Default is
makeIntegerParam("max_depth", lower = 3, upper = 10)), # Default is 6
classif.neuralnet = makeParamSet(makeIntegerVectorParam("hidden", len = 1, lower = 5, upper = 10),
makeNumericParam("threshold", lower = 2, upper = 5, trafo = function(x) {10^x}),
makeNumericParam("stepmax", lower = 2, upper = 2, trafo = function(x) {10^x}))
)
# Validation
desc_tuning <- makeResampleDesc("CV", iters = 4)
control_grid <- makeTuneControlRandom(maxit = 200L) # Default is 100, split between the amount of learners
set.seed(123)
tuning <- makeTuneWrapper(learner = lrn,
resampling = desc_tuning,
par.set = ps,
control = control_grid,
measures = list(tpr),
show.info = TRUE)
parallelStop()
# Parallelize model evaluation (it takes pretty long)
#parallelStartSocket(5) # start in socket mode and create 2 processes on localhost
set.seed(123)
results <- mlr::resample(learner = tuning,
task = classif_task,
resampling = desc_inner,
measures = list(tpr),
models = TRUE,
extract = getTuneResult,
show.info = TRUE)
parallelStop()
res_iters <- getNestedTuneResultsOptPathDf(results)
best_res <- res_iters %>% group_by(selected.learner) %>% slice(which.max(tpr.test.mean)) %>% relocate(tpr.test.mean, .after = selected.learner)
best_res
best_res
g <- ggplot(res_iters, aes(y=tpr.test.mean))
bp3 <- g + geom_boxplot(aes(x=selected.learner))
bp4 <- plotBMRBoxplots(bmr_classif,
measure   = timetrain,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(color = learner.id)
ggarrange(bp1, bp3, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
temp1 <- best_res %>% dplyr::select(selected.learner, tpr.test.mean)
temp1
ggplot(temp1, aes(x=selected.learner, y=tpr.test.mean, color=tpr.test.mean, fill = tpr.test.mean)) +
geom_segment(aes(x=selected.learner, xend=selected.learner, y=0, yend=tpr.test.mean)) +
geom_point(size=3, alpha=0.7, shape=21, stroke=2) +
coord_flip()
bp3 <- plotBMRBoxplots(bmr_classif,
measure   = tpr,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(color = learner.id)
bp4 <- plotBMRBoxplots(bmr_classif,
measure   = timetrain,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(color = learner.id)
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
View(res_iters)
g <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner))
bp3 <- g + geom_boxplot(aes(x=selected.learner))
bp4 <- plotBMRBoxplots(bmr_classif,
measure   = timetrain,
order.lrn = getBMRLearnerIds(bmr_classif))  +
aes(color = learner.id)
ggarrange(bp3, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner))
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
?makeResampleInstance
data_classif <- data %>% dplyr::select(Creatinine, Ejection.Fraction, Event)
classif_task <- makeClassifTask(id = "HeartFailure", data = data_classif, target = "Event", positive = 1)
set.seed(123)
desc_inner <- makeResampleInstance("RepCV", reps = 2,  folds = 4, task = classif_task, stratify = TRUE)
# https://mlr.mlr-org.com/articles/tutorial/integrated_learners.html
classif_measures <- list(tpr, fnr, acc, auc, timetrain)
classif_pipeline <- cpoScaleRange()
## GLM ##
library(h2o)
classif_lrn_glm <- makeLearner("classif.h2o.glm", id = "glm", predict.type = "prob")
classif_lrn_glm <- classif_pipeline %>>% classif_lrn_glm
## Naive Bayes ##
classif_lrn_naive <- makeLearner("classif.naiveBayes", id = "naive", predict.type = "prob")
classif_lrn_naive <- classif_pipeline %>>% classif_lrn_naive
## KNN Model ##
library(kknn)
classif_lrn_knn <- makeLearner("classif.kknn", id = "knn", predict.type = "prob")
classif_lrn_knn <- classif_pipeline %>>% classif_lrn_knn
## LDA ##
library(MASS)
classif_lrn_lda <- makeLearner("classif.lda", id = "LDA", predict.type = "prob")
classif_lrn_lda <- classif_pipeline %>>% classif_lrn_lda
## QDA ##
classif_lrn_qda <- makeLearner("classif.qda", id = "QDA", predict.type = "prob")
classif_lrn_qda <- classif_pipeline %>>% classif_lrn_qda
## Tree(rpart) ##
classif_lrn_rpart <- makeLearner("classif.rpart", id = "rpart", predict.type = "prob")
classif_lrn_rpart <- classif_pipeline %>>% classif_lrn_rpart
## Random Forest ##
classif_lrn_rf <- makeLearner("classif.randomForest", id = "rf", predict.type = "prob")
classif_lrn_rf <- classif_pipeline %>>% classif_lrn_rf
## Ranger ##
classif_lrn_ranger <- makeLearner("classif.ranger", id = "ranger", predict.type = "prob")
classif_lrn_ranger <- classif_pipeline %>>% classif_lrn_ranger
## SVM ##
classif_lrn_SVM <- makeLearner("classif.svm", id = "SVM", predict.type = "prob")
classif_lrn_SVM <- classif_pipeline %>>% classif_lrn_SVM
## Ada Boosting ##
library(ada)
classif_lrn_ada <- makeLearner("classif.ada", id = "ada", predict.type = "prob")
classif_lrn_ada <- classif_pipeline %>>% classif_lrn_ada
## Neural Net ##
# library(neuralnet)
classif_lrn_neuralnet <- makeLearner("classif.neuralnet", id = "neuralnet", predict.type = "prob")
classif_lrn_neuralnet <- classif_pipeline %>>% classif_lrn_neuralnet
## Extreme Gradient Boosting ##
classif_lrn_xgboost <- makeLearner("classif.xgboost", id = "xgboost", predict.type = "prob")
classif_lrn_xgboost <- classif_pipeline %>>% classif_lrn_xgboost
learners <- list(classif_lrn_glm, classif_lrn_naive, classif_lrn_knn, classif_lrn_lda, classif_lrn_qda,
classif_lrn_rpart, classif_lrn_rf, classif_lrn_ranger, classif_lrn_SVM, classif_lrn_ada,
classif_lrn_neuralnet, classif_lrn_xgboost)
library(parallelMap)
parallelStartSocket(2) # start in socket mode and create 2 processes on localhost
set.seed(123)
bmr_classif <- benchmark(learners    = learners,
tasks       = classif_task,
resamplings = desc_inner,
measures    = classif_measures,
models      = TRUE,
show.info   = FALSE)
bmr_classif
parallelStop()
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner))
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner))
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 50, vjust = 0.5, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 50, vjust = 0.5, hjust=1))
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 50, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 50, hjust=1))
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1))
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1), axis.title = FALSE, axis.title.y = "True Positive Rate")
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1), axis.title.x = "", axis.title.y = "True Positive Rate")
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1), axis.title.x = element_blank(), axis.title.y = "True Positive Rate")
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1), axis.title.x = element_blank(), axis.title.y = element_text(True Positive Rate))
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1), axis.title.x = element_blank(), axis.title.y = element_text("True Positive Rate"))
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1))
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1)) +
labs(x = "", y = "True Positive Rate")
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
bp3 <- ggplot(res_iters, aes(y=tpr.test.mean, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1)) +
labs(x = "", y = "True Positive Rate")
bp4 <- ggplot(res_iters, aes(y=exec.time, color = selected.learner)) +
geom_boxplot(aes(x=selected.learner)) +
theme(axis.text.x = element_text(angle = 25, hjust=1)) +
labs(x = "", y = "Execution Time")
ggarrange(bp3, bp4, ncol = 2, nrow = 1, common.legend = TRUE, legend = "right")
View(best_res)
library(rpart)
library(rpart.plot)
install.packages("rpart.plot")
detach(rpart.plot)
=======
library(parallel)
unlink("Project report_cache", recursive = TRUE)
pwd()
>>>>>>> f1e40a6bcd8488a5a815c3f8039a1cd002eedba1
